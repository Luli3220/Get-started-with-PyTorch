{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch 张量（Tensor）\n",
    "张量是一个多维数组，可以是标量、向量、矩阵或更高维度的数据结构。\n",
    "\n",
    "在 PyTorch 中，张量（Tensor）是数据的核心表示形式，类似于 NumPy 的多维数组，但具有更强大的功能，例如支持 GPU 加速和自动梯度计算。\n",
    "\n",
    "张量支持多种数据类型（整型、浮点型、布尔型等）。\n",
    "\n",
    "张量可以存储在 CPU 或 GPU 中，GPU 张量可显著加速计算。\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 方法                     | 说明                                             | 示例代码                                   |\n",
    "|--------------------------|--------------------------------------------------|-------------------------------------------|\n",
    "| `torch.tensor(data)`     | 从 Python 列表或 NumPy 数组创建张量。            | `x = torch.tensor([[1, 2], [3, 4]])`      |\n",
    "| `torch.zeros(size)`      | 创建一个全为零的张量。                           | `x = torch.zeros((2, 3))`                 |\n",
    "| `torch.ones(size)`       | 创建一个全为 1 的张量。                          | `x = torch.ones((2, 3))`                  |\n",
    "| `torch.empty(size)`      | 创建一个未初始化的张量。                         | `x = torch.empty((2, 3))`                 |\n",
    "| `torch.rand(size)`       | 创建一个服从均匀分布的随机张量，值在 [0, 1)。    | `x = torch.rand((2, 3))`                  |\n",
    "| `torch.randn(size)`      | 创建一个服从正态分布的随机张量，均值为 0，标准差为 1。 | `x = torch.randn((2, 3))`             |\n",
    "| `torch.arange(start, end, step)` | 创建一个一维序列张量，类似于 Python 的 range。 | `x = torch.arange(0, 10, 2)`             |\n",
    "| `torch.linspace(start, end, steps)` | 创建一个在指定范围内等间隔的序列张量。      | `x = torch.linspace(0, 1, 5)`            |\n",
    "| `torch.eye(size)`        | 创建一个单位矩阵（对角线为 1，其他为 0）。       | `x = torch.eye(3)`                       |\n",
    "| `torch.from_numpy(ndarray)` | 将 NumPy 数组转换为张量。                      | `x = torch.from_numpy(np.array([1, 2, 3]))` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 torch.tensor() 函数，你可以将一个列表或数组转换为张量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "tensor=torch.tensor([1,2,3])\n",
    "\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你有一个 NumPy 数组，可以使用 torch.from_numpy() 将其转换为张量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np_array=np.array([1,2,3])\n",
    "tensor=torch.from_numpy(np_array)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建 2D 张量（矩阵）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D Tensor (Matrix):\n",
      " tensor([[-9,  4,  2,  5,  7],\n",
      "        [ 3,  0, 12,  8,  6],\n",
      "        [ 1, 23, -6, 45,  2],\n",
      "        [22,  3, -1, 72,  6]])\n",
      "Shape: torch.Size([4, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tensor_2d=torch.tensor(\n",
    "  [[-9, 4, 2, 5, 7],\n",
    "  [3, 0, 12, 8, 6],\n",
    "  [1, 23, -6, 45, 2],\n",
    "  [22, 3, -1, 72, 6]]\n",
    ")\n",
    "\n",
    "print(\"2D Tensor (Matrix):\\n\", tensor_2d)\n",
    "print(\"Shape:\", tensor_2d.shape)  # 形状"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 张量的属性\n",
    "张量的属性如下表："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 属性/方法          | 说明                                   | 示例                     |\n",
    "|--------------------|----------------------------------------|--------------------------|\n",
    "| `.shape`           | 获取张量的形状                         | `tensor.shape`           |\n",
    "| `.size()`          | 获取张量的形状                         | `tensor.size()`          |\n",
    "| `.dtype`           | 获取张量的数据类型                     | `tensor.dtype`           |\n",
    "| `.device`          | 查看张量所在的设备 (CPU/GPU)           | `tensor.device`          |\n",
    "| `.dim()`           | 获取张量的维度数                       | `tensor.dim()`           |\n",
    "| `.requires_grad`   | 是否启用梯度计算                       | `tensor.requires_grad`   |\n",
    "| `.numel()`         | 获取张量中的元素总数                   | `tensor.numel()`         |\n",
    "| `.is_cuda`         | 检查张量是否在 GPU 上                  | `tensor.is_cuda`         |\n",
    "| `.T`               | 获取张量的转置（适用于 2D 张量）       | `tensor.T`               |\n",
    "| `.item()`          | 获取单元素张量的值                     | `tensor.item()`          |\n",
    "| `.is_contiguous()` | 检查张量是否连续存储                   | `tensor.is_contiguous()` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "Tensor.shape: torch.Size([2, 3])\n",
      "Tensor.size(): torch.Size([2, 3])\n",
      "Tensor.dtype: torch.int64\n",
      "Tensor.T tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n"
     ]
    }
   ],
   "source": [
    "import torch  \n",
    "\n",
    "#创建一个二维的张量\n",
    "tensor=torch.tensor([[1,2,3],[4,5,6]])\n",
    "\n",
    "#张量的属性\n",
    "print(\"Tensor:\",tensor)\n",
    "print(\"Tensor.shape:\",tensor.shape)\n",
    "print(\"Tensor.size():\",tensor.size())\n",
    "print(\"Tensor.dtype:\",tensor.dtype)\n",
    "print(\"Tensor.T\",tensor.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 张量的操作\n",
    "张量操作方法说明如下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 操作                     | 说明                                       | 示例代码                     |\n",
    "|--------------------------|--------------------------------------------|------------------------------|\n",
    "| `+, -, *, /`             | 元素级加法、减法、乘法、除法               | `z = x + y`                  |\n",
    "| `torch.matmul(x, y)`      | 矩阵乘法                                   | `z = torch.matmul(x, y)`     |\n",
    "| `torch.dot(x, y)`         | 向量点积（仅适用于 1D 张量）               | `z = torch.dot(x, y)`        |\n",
    "| `torch.sum(x)`            | 求和                                       | `z = torch.sum(x)`           |\n",
    "| `torch.mean(x)`           | 求均值                                     | `z = torch.mean(x)`          |\n",
    "| `torch.max(x)`            | 求最大值                                   | `z = torch.max(x)`           |\n",
    "| `torch.min(x)`            | 求最小值                                   | `z = torch.min(x)`           |\n",
    "| `torch.argmax(x, dim)`    | 返回最大值的索引（指定维度）               | `z = torch.argmax(x, dim=1)` |\n",
    "| `torch.softmax(x, dim)`   | 计算 softmax（指定维度）                   | `z = torch.softmax(x, dim=1)`|\n",
    "| **形状操作**             |                                            |                              |\n",
    "| `torch.reshape(x, shape)` | 改变张量形状                               | `z = torch.reshape(x, (2,3))`|\n",
    "| `torch.squeeze(x)`        | 移除长度为 1 的维度                        | `z = torch.squeeze(x)`       |\n",
    "| `torch.unsqueeze(x, dim)` | 在指定维度增加长度为 1 的维度              | `z = torch.unsqueeze(x, 0)`  |\n",
    "| `torch.transpose(x, dim0, dim1)` | 交换两个维度                      | `z = torch.transpose(x, 0, 1)`|\n",
    "| `torch.cat([x, y], dim)`  | 沿指定维度拼接张量                         | `z = torch.cat([x, y], dim=0)`|\n",
    "| `torch.stack([x, y], dim)`| 沿新维度堆叠张量                           | `z = torch.stack([x, y], dim=0)` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 形状操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 操作                     | 说明                                       | 示例代码                     |\n",
    "|--------------------------|--------------------------------------------|------------------------------|\n",
    "| `x.view(shape)`           | 改变张量的形状（不改变数据）               | `z = x.view(3, 4)`           |\n",
    "| `x.reshape(shape)`        | 类似于 `view`，但更灵活                    | `z = x.reshape(3, 4)`        |\n",
    "| `x.t()`                   | 转置矩阵                                   | `z = x.t()`                  |\n",
    "| `x.unsqueeze(dim)`        | 在指定维度添加一个维度                     | `z = x.unsqueeze(0)`         |\n",
    "| `x.squeeze(dim)`          | 去掉指定维度为 1 的维度                    | `z = x.squeeze(0)`           |\n",
    "| `torch.cat((x, y), dim)`  | 按指定维度连接多个张量                     | `z = torch.cat((x, y), dim=1)`|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始张量:\n",
      " tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n",
      "【索引和切片】\n",
      "获取第一行: tensor([1., 2., 3.])\n",
      "获取第一行第一列的元素: tensor(1.)\n",
      "获取第二列的所有元素: tensor([2., 5.])\n",
      "\n",
      "【形状变换】\n",
      "改变形状后的张量:\n",
      " tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "展平后的张量:\n",
      " tensor([1., 2., 3., 4., 5., 6.])\n",
      "\n",
      "【数学运算】\n",
      "张量加 10:\n",
      " tensor([[11., 12., 13.],\n",
      "        [14., 15., 16.]])\n",
      "张量乘 2:\n",
      " tensor([[ 2.,  4.,  6.],\n",
      "        [ 8., 10., 12.]])\n",
      "张量元素的和: 21.0\n",
      "\n",
      "【与其他张量操作】\n",
      "另一个张量:\n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "矩阵乘法结果:\n",
      " tensor([[ 6.,  6.],\n",
      "        [15., 15.]])\n",
      "\n",
      "【条件判断和筛选】\n",
      "大于 3 的元素的布尔掩码:\n",
      " tensor([[False, False, False],\n",
      "        [ True,  True,  True]])\n",
      "大于 3 的元素:\n",
      " tensor([4., 5., 6.])\n",
      "原始张量 x: tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "最大值索引 tensor_max (dim=1): tensor([2, 2])\n",
      "原始张量 tensor: tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "softmax 结果  (dim=1): tensor([[0.0900, 0.2447, 0.6652],\n",
      "        [0.0900, 0.2447, 0.6652]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个 2D 张量\n",
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32)\n",
    "print(\"原始张量:\\n\", tensor)\n",
    "\n",
    "# 1. **索引和切片操作**\n",
    "print(\"\\n【索引和切片】\")\n",
    "print(\"获取第一行:\", tensor[0])  # 获取第一行\n",
    "print(\"获取第一行第一列的元素:\", tensor[0, 0])  # 获取特定元素\n",
    "print(\"获取第二列的所有元素:\", tensor[:, 1])  # 获取第二列所有元素\n",
    "\n",
    "# 2. **形状变换操作**\n",
    "print(\"\\n【形状变换】\")\n",
    "reshaped = tensor.view(3, 2)  # 改变张量形状为 3x2\n",
    "print(\"改变形状后的张量:\\n\", reshaped)\n",
    "flattened = tensor.flatten()  # 将张量展平成一维\n",
    "print(\"展平后的张量:\\n\", flattened)\n",
    "\n",
    "# 3. **数学运算操作**\n",
    "print(\"\\n【数学运算】\")\n",
    "tensor_add = tensor + 10  # 张量加法\n",
    "print(\"张量加 10:\\n\", tensor_add)\n",
    "tensor_mul = tensor * 2  # 张量乘法\n",
    "print(\"张量乘 2:\\n\", tensor_mul)\n",
    "tensor_sum = tensor.sum()  # 计算所有元素的和\n",
    "print(\"张量元素的和:\", tensor_sum.item())\n",
    "\n",
    "# 4. **与其他张量的操作**\n",
    "print(\"\\n【与其他张量操作】\")\n",
    "tensor2 = torch.tensor([[1, 1, 1], [1, 1, 1]], dtype=torch.float32)\n",
    "print(\"另一个张量:\\n\", tensor2)\n",
    "tensor_dot = torch.matmul(tensor, tensor2.T)  # 张量矩阵乘法\n",
    "print(\"矩阵乘法结果:\\n\", tensor_dot)\n",
    "\n",
    "# 5. **条件判断和筛选**\n",
    "print(\"\\n【条件判断和筛选】\")\n",
    "mask = tensor > 3  # 创建一个布尔掩码\n",
    "print(\"大于 3 的元素的布尔掩码:\\n\", mask)\n",
    "filtered_tensor = tensor[tensor > 3]  # 筛选出符合条件的元素\n",
    "print(\"大于 3 的元素:\\n\", filtered_tensor)\n",
    "\n",
    "# 6. 最大值索引\n",
    "# 在 dim=1 维度（行内）找到最大值的索引\n",
    "tensor_max= torch.argmax(tensor, dim=1)  #行的最大索引    dim=1说明按照列来操作\n",
    "print(\"原始张量 x:\",tensor)\n",
    "print(\"最大值索引 tensor_max (dim=1):\",tensor_max)\n",
    "\n",
    "\n",
    "# 在 dim=1 维度（行内）计算 softmax\n",
    "tensor_softmax = torch.softmax(tensor, dim=1)  \n",
    "print(\"原始张量 tensor:\",tensor)\n",
    "print(\"softmax 结果  (dim=1):\",tensor_softmax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax 计算公式\n",
    "\n",
    "Softmax 是一种常用的激活函数，通常用于多分类问题中，将输入值转换为概率分布。其计算公式如下：\n",
    "\n",
    "$$\n",
    "\\text{softmax}(x_i) = \\frac{\\exp(x_i)}{\\sum_{j=1}^{n} \\exp(x_j)}\n",
    "$$\n",
    "\n",
    "其中：\n",
    "- $ x_i $: 输入张量中的某个元素。\n",
    "- $ \\exp(x_i) $: 指数函数，$ e^{x_i} $。\n",
    "- $ \\sum_{j=1}^{n} \\exp(x_j) $: 同一维度上所有元素的指数和。\n",
    "- $ n $: 同一维度上的元素总数。\n",
    "\n",
    "#### 特性\n",
    "1. **范围**: Softmax 输出的每个值都在 $[0, 1]$ 范围内。\n",
    "2. **归一化**: 同一维度上的输出值之和为 1，形成一个概率分布。\n",
    "\n",
    "#### 示例\n",
    "假设输入张量为 $ x = [x_1, x_2, x_3] $，则 softmax 的计算过程如下：\n",
    "\n",
    "$$\n",
    "\\text{softmax}(x_1) = \\frac{\\exp(x_1)}{\\exp(x_1) + \\exp(x_2) + \\exp(x_3)}\n",
    "$$\n",
    "$$\n",
    "\\text{softmax}(x_2) = \\frac{\\exp(x_2)}{\\exp(x_1) + \\exp(x_2) + \\exp(x_3)}\n",
    "$$\n",
    "$$\n",
    "\\text{softmax}(x_3) = \\frac{\\exp(x_3)}{\\exp(x_1) + \\exp(x_2) + \\exp(x_3)}\n",
    "$$\n",
    "\n",
    "最终输出为：\n",
    "\n",
    "$$\n",
    "\\text{softmax}(x) = [\\text{softmax}(x_1), \\text{softmax}(x_2), \\text{softmax}(x_3)]\n",
    "$$\n",
    "\n",
    "#### 应用场景\n",
    "- 多分类任务中，用于计算每个类别的概率。\n",
    "- 神经网络的最后一层，结合交叉熵损失函数使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 张量与 NumPy 的互操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 操作                     | 说明                                   | 示例代码                          |\n",
    "|--------------------------|----------------------------------------|-----------------------------------|\n",
    "| `torch.from_numpy(ndarray)` | 将 NumPy 数组转换为张量。              | `x = torch.from_numpy(np_array)` |\n",
    "| `x.numpy()`               | 将张量转换为 NumPy 数组（仅限 CPU 张量）。 | `np_array = x.numpy()`           |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. NumPy 转为 PyTorch 张量\n",
      "NumPy 数组:\n",
      " [[1 2 3]\n",
      " [4 5 6]]\n",
      "转换后的 PyTorch 张量:\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]], dtype=torch.int32)\n",
      "修改后的 NumPy 数组:\n",
      " [[100   2   3]\n",
      " [  4   5   6]]\n",
      "PyTorch 张量也会同步变化:\n",
      " tensor([[100,   2,   3],\n",
      "        [  4,   5,   6]], dtype=torch.int32)\n",
      "\n",
      "2. PyTorch 张量转为 NumPy 数组\n",
      "PyTorch 张量:\n",
      " tensor([[ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n",
      "转换后的 NumPy 数组:\n",
      " [[ 7.  8.  9.]\n",
      " [10. 11. 12.]]\n",
      "修改后的 PyTorch 张量:\n",
      " tensor([[77.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n",
      "NumPy 数组也会同步变化:\n",
      " [[77.  8.  9.]\n",
      " [10. 11. 12.]]\n",
      "\n",
      "3. 使用 clone() 保证独立数据\n",
      "原始张量:\n",
      " tensor([[13., 14., 15.],\n",
      "        [16., 17., 18.]])\n",
      "修改后的张量:\n",
      " tensor([[ 0., 14., 15.],\n",
      "        [16., 17., 18.]])\n",
      "NumPy 数组（不会同步变化）:\n",
      " [[13. 14. 15.]\n",
      " [16. 17. 18.]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 1. NumPy 数组转换为 PyTorch 张量\n",
    "print(\"1. NumPy 转为 PyTorch 张量\")\n",
    "numpy_array = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(\"NumPy 数组:\\n\", numpy_array)\n",
    "\n",
    "# 使用 torch.from_numpy() 将 NumPy 数组转换为张量\n",
    "tensor_from_numpy = torch.from_numpy(numpy_array)\n",
    "print(\"转换后的 PyTorch 张量:\\n\", tensor_from_numpy)\n",
    "\n",
    "# 修改 NumPy 数组，观察张量的变化（共享内存）\n",
    "numpy_array[0, 0] = 100\n",
    "print(\"修改后的 NumPy 数组:\\n\", numpy_array)\n",
    "print(\"PyTorch 张量也会同步变化:\\n\", tensor_from_numpy)\n",
    "\n",
    "# 2. PyTorch 张量转换为 NumPy 数组\n",
    "print(\"\\n2. PyTorch 张量转为 NumPy 数组\")\n",
    "tensor = torch.tensor([[7, 8, 9], [10, 11, 12]], dtype=torch.float32)\n",
    "print(\"PyTorch 张量:\\n\", tensor)\n",
    "\n",
    "# 使用 tensor.numpy() 将张量转换为 NumPy 数组\n",
    "numpy_from_tensor = tensor.numpy()\n",
    "print(\"转换后的 NumPy 数组:\\n\", numpy_from_tensor)\n",
    "\n",
    "# 修改张量，观察 NumPy 数组的变化（共享内存）\n",
    "tensor[0, 0] = 77\n",
    "print(\"修改后的 PyTorch 张量:\\n\", tensor)\n",
    "print(\"NumPy 数组也会同步变化:\\n\", numpy_from_tensor)\n",
    "\n",
    "# 3. 注意：不共享内存的情况（需要复制数据）\n",
    "print(\"\\n3. 使用 clone() 保证独立数据\")\n",
    "tensor_independent = torch.tensor([[13, 14, 15], [16, 17, 18]], dtype=torch.float32)\n",
    "numpy_independent = tensor_independent.clone().numpy()  # 使用 clone 复制数据\n",
    "print(\"原始张量:\\n\", tensor_independent)\n",
    "tensor_independent[0, 0] = 0  # 修改张量数据\n",
    "print(\"修改后的张量:\\n\", tensor_independent)\n",
    "print(\"NumPy 数组（不会同步变化）:\\n\", numpy_independent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
